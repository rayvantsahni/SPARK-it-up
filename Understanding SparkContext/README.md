# Understanding SparkContext
A SparkContext represents the entry point to Spark functionality. It's like a key to the house. PySpark automatically creates a `SparkContext` for you in the PySpark shell (so you don't have to create it by yourself) and is exposed via a variable `sc`.
